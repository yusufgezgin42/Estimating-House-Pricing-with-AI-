import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
import re
from collections import Counter
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
import numpy as np
from datetime import datetime
import warnings
from typing import List, Dict, Tuple, Optional
import json
warnings.filterwarnings('ignore')

# ==================== BLOOMBERGHT CRAWLER KODU ====================

BASE_URL = "https://www.bloomberght.com"
NEWS_LIST_URL = f"{BASE_URL}/haberler"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
}

TITLE_KEYWORDS = [
    "konut",
    "gayrimenkul",
    "kira",
    "konut fiyat",
    "konut kredisi",
    "kfe",  # konut fiyat endeksi
]

COUNTRY_CITY_KEYWORDS = [
    "tÃ¼rkiye",
    "istanbul",
    "TÃ¼rkiye Cumhuriyet Merkez BankasÄ± (TCMB)"
]

def fetch_listing_html():
    resp = requests.get(NEWS_LIST_URL, headers=HEADERS, timeout=10)
    resp.raise_for_status()
    return resp.text

def fetch_article_raw(url: str) -> BeautifulSoup:
    resp = requests.get(url, headers=HEADERS, timeout=10)
    resp.raise_for_status()
    return BeautifulSoup(resp.text, "html.parser")

def is_tr_istanbul_related(soup: BeautifulSoup) -> bool:
    """Haber gÃ¶vdesinde TÃ¼rkiye / Ä°stanbul geÃ§iyor mu?"""
    full_text = soup.get_text(" ", strip=True).lower()
    return any(kw in full_text for kw in COUNTRY_CITY_KEYWORDS)

def find_tr_istanbul_real_estate_links(max_results=20):
    html = fetch_listing_html()
    soup = BeautifulSoup(html, "html.parser")

    candidates = []

    for a in soup.find_all("a"):
        title = a.get_text(strip=True)
        href = a.get("href")

        if not title or not href:
            continue

        t_lower = title.lower()

        # BaÅŸlÄ±kta konutla ilgili bir ÅŸey yoksa geÃ§
        if not any(kw in t_lower for kw in TITLE_KEYWORDS):
            continue

        # URL tam hale getir
        if href.startswith("//"):
            href = "https:" + href
        elif href.startswith("/"):
            href = urljoin(BASE_URL, href)

        if not href.startswith(BASE_URL):
            continue

        candidates.append({"title": title, "url": href})

    # URL bazlÄ± uniq
    uniq = {}
    for item in candidates:
        uniq[item["url"]] = item["title"]
    deduped = [{"url": u, "title": t} for u, t in uniq.items()]

    # Åimdi her biri iÃ§in sayfa Ã§ek, "TÃ¼rkiye/Ä°stanbul iÃ§ermeyenleri" at
    filtered = []
    for item in deduped:
        try:
            soup_article = fetch_article_raw(item["url"])
        except Exception as e:
            print("Hata (Ã¶n kontrol):", e)
            continue

        if is_tr_istanbul_related(soup_article):
            filtered.append(item)

        if len(filtered) >= max_results:
            break
        time.sleep(0.7)

    return filtered

def parse_article_text(soup: BeautifulSoup) -> str:
    """ParagraflarÄ± birleÅŸtirerek temiz bir metin dÃ¶ndÃ¼r."""
    paragraphs = [p.get_text(" ", strip=True) for p in soup.find_all("p")]
    text = " ".join(paragraphs)
    return text

def extract_tr_ist_features_from_text(text: str) -> dict:
    """
    BloombergHT konut haberi metninden TÃ¼rkiye geneli ve Ä°stanbul iÃ§in
    bazÄ± sayÄ±sal Ã¶zellikleri Ã§ekmeye Ã§alÄ±ÅŸÄ±r.
    """
    t = text.lower()
    features = {
        "tr_yoy_change": None,
        "tr_mom_change": None,
        "tr_index_level": None,
        "ist_yoy_change": None,
        "ist_mom_change": None,
    }

    # 1) TÃ¼rkiye iÃ§in yÄ±llÄ±k artÄ±ÅŸ (yÃ¼zde 32,2 / %32,2 / yÃ¼zde 32.2)
    # pattern: "tÃ¼rkiye genelinde ... yÃ¼zde xx,x" veya "bir Ã¶nceki yÄ±lÄ±n aynÄ± ayÄ±na gÃ¶re ... yÃ¼zde xx,x"
    m_tr_yoy = re.search(
        r"(tÃ¼rkiye(?: genelinde)?|konut fiyat endeksi).*?(yÃ¼zde|%)[\s]*([\d]+[.,]\d+)",
        t
    )
    if not m_tr_yoy:
        # yedek: "bir Ã¶nceki yÄ±lÄ±n aynÄ± ayÄ±na gÃ¶re nominal olarak yÃ¼zde 32,2"
        m_tr_yoy = re.search(
            r"bir Ã¶nceki yÄ±lÄ±n aynÄ± ayÄ±na gÃ¶re.*?(yÃ¼zde|%)[\s]*([\d]+[.,]\d+)",
            t
        )
        if m_tr_yoy:
            value = m_tr_yoy.group(2)
            features["tr_yoy_change"] = float(value.replace(",", "."))
    else:
        value = m_tr_yoy.group(3)
        features["tr_yoy_change"] = float(value.replace(",", "."))

    # 2) TÃ¼rkiye iÃ§in aylÄ±k artÄ±ÅŸ (bir Ã¶nceki aya gÃ¶re yÃ¼zde 1,7 artan KFE)
    m_tr_mom = re.search(
        r"bir Ã¶nceki aya gÃ¶re.*?(yÃ¼zde|%)[\s]*([\d]+[.,]\d+)\s*oranÄ±nda artan kfe",
        t
    )
    if m_tr_mom:
        value = m_tr_mom.group(2)
        features["tr_mom_change"] = float(value.replace(",", "."))

    # 3) KFE seviye (195,7 seviyesine yÃ¼kseldi)
    m_index = re.search(
        r"kfe.*?([\d]+[.,]\d+)\s*seviyesine",
        t
    )
    if m_index:
        value = m_index.group(1)
        features["tr_index_level"] = float(value.replace(",", "."))

    # 4) Ä°stanbul iÃ§in yÄ±llÄ±k artÄ±ÅŸ (haberlerde genelde "istanbul'da yÄ±llÄ±k artÄ±ÅŸ %xx,x")
    m_ist_yoy = re.search(
        r"istanbul.*?(yÄ±llÄ±k|yÄ±l bazÄ±nda).*?(yÃ¼zde|%)[\s]*([\d]+[.,]\d+)",
        t
    )
    if m_ist_yoy:
        value = m_ist_yoy.group(3)
        features["ist_yoy_change"] = float(value.replace(",", "."))

    # 5) Ä°stanbul iÃ§in aylÄ±k artÄ±ÅŸ (daha nadir ama koyalÄ±m)
    m_ist_mom = re.search(
        r"istanbul.*?bir Ã¶nceki aya gÃ¶re.*?(yÃ¼zde|%)[\s]*([\d]+[.,]\d+)",
        t
    )
    if m_ist_mom:
        value = m_ist_mom.group(2)
        features["ist_mom_change"] = float(value.replace(",", "."))

    return features

def crawl_bloomberght_konut_tr_ist(max_results=3, delay_seconds=1.0):
    """
    1) BloombergHT haber listesinden sadece baÅŸlÄ±ÄŸÄ± konutla ilgili
       ve metni TÃ¼rkiye/Ä°stanbul iÃ§eren haberleri bulur.
    2) En fazla 'max_results' kadar haber dÃ¶ndÃ¼rÃ¼r. (VarsayÄ±lan: 3)
    """
    links = find_tr_istanbul_real_estate_links(max_results=10)  # geniÅŸ tutuyoruz

    results = []
    for item in links:

        # â—ï¸ 3 HABER LÄ°MÄ°TÄ°
        if len(results) >= max_results:
            break

        url = item["url"]
        print(f"Haber Ã§ekiliyor: {item['title']} â†’ {url}")

        try:
            soup = fetch_article_raw(url)

            # BaÅŸlÄ±k
            title_tag = soup.find("h1")
            title = title_tag.get_text(strip=True) if title_tag else item["title"]

            # GiriÅŸ tarihi (Ã§ok kaba, ama iÅŸ gÃ¶rÃ¼r)
            full_text = soup.get_text("\n", strip=True)
            giris = None
            m_giris = re.search(r"GiriÅŸ:\s*(.+)", full_text)
            if m_giris:
                giris = m_giris.group(1).strip()

            # Metin
            text = parse_article_text(soup)

            # Feature Ã§Ä±kar
            features = extract_tr_ist_features_from_text(text)

            results.append({
                "url": url,
                "title": title,
                "giris": giris,
                "text": text,
                "features": features
            })

        except Exception as e:
            print("Hata:", e)

        time.sleep(delay_seconds)

    return results

# ==================== NLP ANALÄ°Z KODU ====================

# NLTK verilerini indir (ilk Ã§alÄ±ÅŸtÄ±rmada gerekli)
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('punkt_tab', quiet=True)
except:
    pass

class ImprovedTurkishNLPAnalyzer:
    def __init__(self):
        # TÃ¼rkÃ§e stopwords
        self.turkish_stopwords = set(stopwords.words('turkish'))
        # Ek stopwords ekleyelim
        self.turkish_stopwords.update([
            'bir', 've', 'ile', 'olarak', 'iÃ§in', 'kadar', 'gÃ¶re',
            'da', 'de', 'bu', 'ÅŸu', 'o', 'ise', 'mi', 'mÄ±', 'mu', 'mÃ¼',
            'haber', 'haberi', 'haberler', 'bloomberg', 'ht', 'tcmb',
            'ise', 'iken', 'ile', 'idi', 'imiÅŸ', 'yok', 'var', 'dÄ±r',
            'dir', 'dur', 'dÃ¼r', 'tÄ±r', 'tir', 'tur', 'tÃ¼r'
        ])
        
        # Anahtar kelime kategorileri - GÃœNCELLENMÄ°Å
        self.keyword_categories = {
            'faiz': ['faiz', 'faizi', 'faizler', 'faizleri', 'faiz oranÄ±', 'faiz indirimi', 
                    'faiz artÄ±ÅŸÄ±', 'politika faizi', 'referans faiz', 'tcmb'],
            
            'kredi': ['kredi', 'kredisi', 'krediler', 'konut kredisi', 'mortgage', 
                     'ipotek', 'kredi faizi', 'kredi oranÄ±', 'kredi talebi'],
            
            'fiyat': ['fiyat', 'fiyatÄ±', 'fiyatlar', 'fiyatlarÄ±', 'konut fiyatÄ±', 
                     'ev fiyatÄ±', 'kira fiyatÄ±', 'fiyat artÄ±ÅŸÄ±', 'fiyat dÃ¼ÅŸÃ¼ÅŸÃ¼',
                     'fiyat endeksi', 'kfe'],
            
            'enflasyon': ['enflasyon', 'enflasyonu', 'enflasyonda', 'enflasyonist',
                         'reel', 'nominal', 'enflasyon baskÄ±sÄ±', 'reel deÄŸer'],
            
            'talep': ['talep', 'talebi', 'talep artÄ±ÅŸÄ±', 'talepte', 'talep yÃ¶nelimi',
                     'tÃ¼ketici talebi', 'yatÄ±rÄ±mcÄ± talebi', 'arttÄ±', 'artÄ±ÅŸ'],
            
            'arz': ['arz', 'arzÄ±', 'arz azlÄ±ÄŸÄ±', 'arz fazlasÄ±', 'arz-talep', 
                   'piyasa arzÄ±', 'konut arzÄ±'],
            
            'semt_bÃ¶lge': ['istanbul', 'ankara', 'izmir', 'kadÄ±kÃ¶y', 'beÅŸiktaÅŸ',
                          'ÅŸiÅŸli', 'avrupa yakasÄ±', 'anadolu yakasÄ±', 'bÃ¶lge',
                          'semt', 'ilÃ§e', 'mahalle'],
            
            'ekonomi': ['ekonomi', 'ekonomik', 'bÃ¼yÃ¼me', 'gsyh', 'yatÄ±rÄ±m',
                       'piyasa', 'finans', 'ekonomi politikasÄ±', 'merkez bankasÄ±'],
            
            'deÄŸer': ['deÄŸer', 'deÄŸeri', 'deÄŸer artÄ±ÅŸÄ±', 'deÄŸer kaybÄ±', 'deÄŸerleme',
                     'deÄŸer saklama', 'yatÄ±rÄ±m deÄŸeri', 'reel deÄŸer'],
            
            'risk': ['risk', 'riski', 'riskler', 'risk faktÃ¶rÃ¼', 'risk algÄ±sÄ±',
                    'belirsizlik', 'volatilite', 'istikrar', 'kayÄ±p', 'kaybÄ±']
        }
        
        # Duygu yÃ¼klÃ¼ kelimeler - GÃœNCELLENMÄ°Å
        self.sentiment_words = {
            'pozitif': ['artÄ±ÅŸ', 'yÃ¼kseliÅŸ', 'kazanÃ§', 'getiri', 'olumlu', 'iyi',
                       'gÃ¼Ã§lÃ¼', 'cazip', 'avantaj', 'fÄ±rsat', 'talep', 'bÃ¼yÃ¼me',
                       'geliÅŸme', 'iyileÅŸme', 'kazandÄ±rÄ±yor', 'kazanÃ§lÄ±', 'artan',
                       'yÃ¼kseldi', 'arttÄ±', 'pozitif', 'yukarÄ±', 'gÃ¼Ã§lÃ¼'],
            
            'negatif': ['dÃ¼ÅŸÃ¼ÅŸ', 'kayÄ±p', 'zarar', 'risk', 'olumsuz', 'kÃ¶tÃ¼',
                       'zayÄ±f', 'tehlike', 'dezavantaj', 'tehdit', 'azalma',
                       'gerileme', 'kaybediyor', 'zararlÄ±', 'dÃ¼ÅŸÃ¼k', 'kaybÄ±',
                       'dÃ¼ÅŸtÃ¼', 'azaldÄ±', 'negatif', 'aÅŸaÄŸÄ±', 'zayÄ±f', 'kayÄ±p'],
            
            'nÃ¶tr': ['stabil', 'duraÄŸan', 'sabit', 'koruma', 'beklenti', 'tahmin',
                    'projeksiyon', 'Ã¶ngÃ¶rÃ¼', 'bekleniyor', 'nominal', 'reel',
                    'endeks', 'seviye', 'oran', 'yÃ¼zde']
        }
    
    def preprocess_text(self, text: str, use_stemming: bool = False) -> List[str]:
        """Metni temizle ve token'lara ayÄ±r"""
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        
        # Ã–zel karakterleri temizle (sayÄ±larÄ± koru)
        text = re.sub(r'[^\w\s%.,]', ' ', text)
        
        try:
            # Tokenize
            tokens = word_tokenize(text, language='turkish')
        except:
            # Fallback: basit split
            tokens = text.split()
        
        # Stopwords'leri ve kÄ±sa kelimeleri kaldÄ±r
        tokens = [token for token in tokens 
                 if token not in self.turkish_stopwords 
                 and len(token) > 2 
                 and not token.isdigit()]
        
        # KÃ¶k bulmayÄ± kaldÄ±rdÄ±k - Ã§ok agresifti
        # Sadece basit son ekleri kaldÄ±r
        if use_stemming:
            tokens = [self._simple_stem(token) for token in tokens]
        
        return tokens
    
    def _simple_stem(self, word: str) -> str:
        """Ã‡ok basit kÃ¶k bulma - sadece son 'ler', 'lar', 'Ä±', 'i', 'u', 'Ã¼' eklerini kaldÄ±r"""
        if len(word) <= 3:
            return word
        
        # Sadece Ã§oÄŸul eklerini kaldÄ±r
        if word.endswith(('ler', 'lar')):
            return word[:-3]
        if word.endswith(('larÄ±', 'leri')):
            return word[:-4]
        
        return word
    
    def extract_keywords(self, text: str, top_n: int = 20) -> Dict:
        """Metinden anahtar kelimeler Ã§Ä±kar"""
        # KÃ¶k bulma OLMADAN
        tokens = self.preprocess_text(text, use_stemming=False)
        
        # Kelime frekanslarÄ±
        word_freq = Counter(tokens)
        
        # Kategori bazlÄ± anahtar kelimeleri bul
        category_keywords = {}
        text_lower = text.lower()
        
        for category, keywords in self.keyword_categories.items():
            found_keywords = []
            for keyword in keywords:
                if keyword in text_lower:
                    found_keywords.append(keyword)
            if found_keywords:
                category_keywords[category] = found_keywords
        
        # En sÄ±k geÃ§en kelimeler
        top_keywords = dict(word_freq.most_common(top_n))
        
        return {
            'top_keywords': top_keywords,
            'category_keywords': category_keywords,
            'total_tokens': len(tokens),
            'unique_tokens': len(set(tokens))
        }
    
    def analyze_sentiment(self, text: str) -> Dict:
        """GeliÅŸmiÅŸ duygu analizi"""
        try:
            sentences = sent_tokenize(text, language='turkish')
        except:
            # Basit cÃ¼mle bÃ¶lme
            sentences = re.split(r'[.!?]+', text)
        
        # BaÅŸlÄ±k sentiment'i iÃ§in Ã¶zel kontrol
        sentiment_scores = {
            'pozitif': 0,
            'negatif': 0,
            'nÃ¶tr': 0
        }
        
        # BaÅŸlÄ±kta negatif kelimeler varsa ek puan
        title_negatives = ['kayÄ±p', 'kaybÄ±', 'dÃ¼ÅŸÃ¼ÅŸ', 'zarar', 'kÃ¶tÃ¼', 'olumsuz']
        for word in title_negatives:
            if word in text[:100].lower():  # Ä°lk 100 karakter (baÅŸlÄ±k ve giriÅŸ)
                sentiment_scores['negatif'] += 2
        
        # Her cÃ¼mle iÃ§in sentiment analizi
        sentence_sentiments = []
        for sentence in sentences:
            if len(sentence.strip()) < 5:
                continue
                
            sentence_lower = sentence.lower()
            sentence_score = {'pozitif': 0, 'negatif': 0, 'nÃ¶tr': 0}
            
            # Kelime bazlÄ± sentiment
            for sentiment, words in self.sentiment_words.items():
                for word in words:
                    if word in sentence_lower:
                        sentence_score[sentiment] += 1
            
            # Finansal terimler iÃ§in ek puan
            financial_positives = ['artÄ±ÅŸ', 'artan', 'yÃ¼kseliÅŸ', 'bÃ¼yÃ¼me', 'olumlu']
            financial_negatives = ['dÃ¼ÅŸÃ¼ÅŸ', 'azalan', 'kayÄ±p', 'kaybÄ±', 'olumsuz']
            
            for word in financial_positives:
                if word in sentence_lower:
                    sentence_score['pozitif'] += 2
            
            for word in financial_negatives:
                if word in sentence_lower:
                    sentence_score['negatif'] += 2
            
            # CÃ¼mlenin dominant sentiment'i
            if sentence_score['pozitif'] > sentence_score['negatif']:
                sentence_sentiments.append('pozitif')
            elif sentence_score['negatif'] > sentence_score['pozitif']:
                sentence_sentiments.append('negatif')
            else:
                sentence_sentiments.append('nÃ¶tr')
            
            # Toplam sentiment puanlarÄ±na ekle
            for sentiment in sentiment_scores:
                sentiment_scores[sentiment] += sentence_score[sentiment]
        
        # Toplam sentiment belirleme
        total = sum(sentiment_scores.values())
        if total > 0:
            sentiment_ratio = {k: v/total for k, v in sentiment_scores.items()}
            
            # AÄŸÄ±rlÄ±klÄ± sentiment belirle
            weighted_scores = {
                'pozitif': sentiment_scores['pozitif'] * 1.0,
                'negatif': sentiment_scores['negatif'] * 1.2,  # Negatife daha fazla aÄŸÄ±rlÄ±k
                'nÃ¶tr': sentiment_scores['nÃ¶tr'] * 0.5
            }
            dominant_sentiment = max(weighted_scores.items(), key=lambda x: x[1])[0]
        else:
            sentiment_ratio = {'pozitif': 0, 'negatif': 0, 'nÃ¶tr': 1}
            dominant_sentiment = 'nÃ¶tr'
        
        return {
            'sentiment_scores': sentiment_scores,
            'sentiment_ratio': sentiment_ratio,
            'dominant_sentiment': dominant_sentiment,
            'sentence_sentiments': sentence_sentiments,
            'positive_sentences': len([s for s in sentence_sentiments if s == 'pozitif']),
            'negative_sentences': len([s for s in sentence_sentiments if s == 'negatif']),
            'neutral_sentences': len([s for s in sentence_sentiments if s == 'nÃ¶tr'])
        }
    
    def extract_financial_entities(self, text: str) -> Dict:
        """Finansal varlÄ±klarÄ± ve sayÄ±sal verileri Ã§Ä±kar - GELÄ°ÅTÄ°RÄ°LMÄ°Å"""
        # GeliÅŸmiÅŸ yÃ¼zde oranlarÄ± bulma
        percentages = []
        
        # Pattern 1: "yÃ¼zde 32,2" 
        matches1 = re.findall(r'yÃ¼zde\s+(\d+[.,]?\d*)', text.lower())
        percentages.extend([float(m.replace(',', '.')) for m in matches1])
        
        # Pattern 2: "%32,2"
        matches2 = re.findall(r'%(\d+[.,]?\d*)', text.lower())
        percentages.extend([float(m.replace(',', '.')) for m in matches2])
        
        # Pattern 3: "oranÄ±nda 32,2"
        matches3 = re.findall(r'oranÄ±nda\s+(\d+[.,]?\d*)', text.lower())
        percentages.extend([float(m.replace(',', '.')) for m in matches3])
        
        # TÃ¼m sayÄ±larÄ± bul (binlik, milyonluk deÄŸerler)
        all_numbers = re.findall(r'\b(\d+[.,]?\d*)\b', text)
        numbers = []
        for n in all_numbers:
            try:
                num = float(n.replace(',', '.'))
                if num > 1:  # 1'den bÃ¼yÃ¼k sayÄ±larÄ± al
                    numbers.append(num)
            except:
                pass
        
        # Para birimleri
        currency_patterns = {
            'tl': r'(\d+[.,]?\d*)\s*(tl|â‚º|tÃ¼rk lirasÄ±)',
            'dolar': r'(\d+[.,]?\d*)\s*(\$|dolar|usd)',
            'euro': r'(\d+[.,]?\d*)\s*(â‚¬|euro|eur)'
        }
        
        currency_values = {}
        for currency, pattern in currency_patterns.items():
            matches = re.findall(pattern, text.lower())
            if matches:
                currency_values[currency] = [float(m[0].replace(',', '.')) for m in matches]
        
        # Zaman ifadeleri
        time_expressions = re.findall(
            r'(\d+\s*(ay|yÄ±l|hafta|gÃ¼n|saat)\s*(Ã¶nce|iÃ§inde|sonra)?)', 
            text.lower()
        )
        
        # KFE (Konut Fiyat Endeksi) deÄŸerleri
        kfe_values = re.findall(r'kfe.*?(\d+[.,]?\d+)', text.lower())
        kfe_values = [float(v.replace(',', '.')) for v in kfe_values]
        
        return {
            'percentages': percentages,
            'significant_numbers': numbers[:20],
            'currency_values': currency_values,
            'time_expressions': time_expressions,
            'kfe_values': kfe_values,
            'max_percentage': max(percentages) if percentages else None,
            'min_percentage': min(percentages) if percentages else None,
            'avg_percentage': np.mean(percentages) if percentages else None,
            'total_percentages': len(percentages)
        }
    
    def analyze_temporal_context(self, text: str, publish_date: Optional[str] = None) -> Dict:
        """Zamansal baÄŸlam analizi"""
        temporal_keywords = {
            'kÄ±sa_vade': ['kÄ±sa vadede', 'yakÄ±n dÃ¶nemde', 'Ã¶nÃ¼mÃ¼zdeki ay', 'birkaÃ§ ay iÃ§inde',
                         '3 ay', '6 ay', 'kÄ±sa sÃ¼rede', 'yakÄ±n zamanda'],
            
            'orta_vade': ['orta vadede', 'gelecek yÄ±l', '12 ay', '1 yÄ±l iÃ§inde',
                         'Ã¶nÃ¼mÃ¼zdeki yÄ±l', 'orta dÃ¶nemde'],
            
            'uzun_vade': ['uzun vadede', '2 yÄ±l', '5 yÄ±l', 'uzun dÃ¶nemde',
                         'gelecek yÄ±llarda', 'uzun sÃ¼reli']
        }
        
        time_context = {}
        for period, keywords in temporal_keywords.items():
            count = sum(1 for keyword in keywords if keyword in text.lower())
            time_context[period] = count
        
        # YayÄ±n tarihi analizi
        date_analysis = {}
        if publish_date:
            try:
                # Tarihi parse et
                if 'giriÅŸ' in publish_date.lower():
                    date_str = publish_date.split(':')[-1].strip()
                else:
                    date_str = publish_date
                
                # Tarihi parse etmeye Ã§alÄ±ÅŸ
                date_formats = ['%d %B %Y', '%d.%m.%Y', '%d/%m/%Y', '%Y-%m-%d']
                parsed_date = None
                
                for fmt in date_formats:
                    try:
                        parsed_date = datetime.strptime(date_str, fmt)
                        break
                    except:
                        continue
                
                if parsed_date:
                    date_analysis = {
                        'published_date': parsed_date.strftime('%Y-%m-%d'),
                        'days_ago': (datetime.now() - parsed_date).days,
                        'recency': 'recent' if (datetime.now() - parsed_date).days <= 7 else 'old'
                    }
            except:
                pass
        
        return {
            'time_context': time_context,
            'dominant_timeframe': max(time_context.items(), key=lambda x: x[1])[0] if any(time_context.values()) else 'bilinmiyor',
            'date_analysis': date_analysis
        }


class ImprovedHousingNewsAnalyzer:
    """GeliÅŸmiÅŸ konut haberleri analiz sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.nlp_analyzer = ImprovedTurkishNLPAnalyzer()
        
        # GeliÅŸmiÅŸ karar kurallarÄ±
        self.decision_rules = {
            'K1': {
                'name': 'DÃ¼ÅŸÃ¼k Kredi Faizi ve Talep ArtÄ±ÅŸÄ±',
                'keywords': ['faiz indirimi', 'faiz oranÄ±', 'kredi oranÄ±', 'talep artÄ±ÅŸÄ±', 
                           'mortgage', 'tcmb', 'politika faizi'],
                'score': 3,
                'description': 'DÃ¼ÅŸÃ¼k faiz ortamÄ± ve artan talep'
            },
            'K2': {
                'name': 'Arz AzlÄ±ÄŸÄ± ve Fiyat ArtÄ±ÅŸÄ±',
                'keywords': ['arz azlÄ±ÄŸÄ±', 'fiyat artÄ±ÅŸÄ±', 'konut fiyatÄ±', 'kira artÄ±ÅŸÄ±',
                           'konut fiyat endeksi', 'kfe', 'arttÄ±', 'yÃ¼kseldi'],
                'score': 2,
                'description': 'Arz kÄ±sÄ±tlÄ±lÄ±ÄŸÄ± fiyatlarÄ± yukarÄ± Ã§ekiyor'
            },
            'K3': {
                'name': 'Enflasyona KarÅŸÄ± Koruma',
                'keywords': ['enflasyon', 'deÄŸer saklama', 'yatÄ±rÄ±m aracÄ±', 'koruma',
                           'reel deÄŸer', 'enflasyon baskÄ±sÄ±'],
                'score': 1,
                'description': 'Gayrimenkul enflasyona karÅŸÄ± koruma saÄŸlÄ±yor'
            },
            'K4': {
                'name': 'AÅŸÄ±rÄ± DeÄŸerlenme Riski',
                'keywords': ['aÅŸÄ±rÄ± deÄŸerlenme', 'balon', 'risk', 'dÃ¼ÅŸÃ¼ÅŸ riski',
                           'kayÄ±p', 'kaybÄ±', 'dÃ¼ÅŸÃ¼ÅŸ', 'zarar'],
                'score': -2,  # Daha gÃ¼Ã§lÃ¼ negatif etki
                'description': 'AÅŸÄ±rÄ± deÄŸerlenme riski mevcut'
            },
            'K5': {
                'name': 'Ä°stanbul Ã–zelinde GÃ¼Ã§lÃ¼ Performans',
                'keywords': ['istanbul', 'kadÄ±kÃ¶y', 'beÅŸiktaÅŸ', 'avrupa yakasÄ±',
                           'anadolu yakasÄ±', 'semt', 'bÃ¶lge'],
                'score': 1,
                'description': 'Ä°stanbul Ã¶zelinde gÃ¼Ã§lÃ¼ performans'
            },
            'K6': {
                'name': 'YÃ¼ksek ArtÄ±ÅŸ OranlarÄ±',
                'keywords': ['yÃ¼zde', '%', 'oranÄ±nda', 'artÄ±ÅŸ', 'yÃ¼kseliÅŸ'],
                'score': 1,
                'description': 'YÃ¼ksek yÃ¼zdelik artÄ±ÅŸ oranlarÄ±'
            }
        }
    
    def analyze_article(self, article: Dict) -> Dict:
        """Tek bir haberi kapsamlÄ± analiz et"""
        
        text = article.get('text', '')
        title = article.get('title', '')
        publish_date = article.get('giris', '')
        
        print(f"\nğŸ“ Analiz edilen metin Ã¶zeti: {text[:200]}...")
        
        # 1. Anahtar kelime analizi
        keywords = self.nlp_analyzer.extract_keywords(text + ' ' + title)
        
        # 2. Duygu analizi
        sentiment = self.nlp_analyzer.analyze_sentiment(text)
        
        # 3. Finansal varlÄ±k Ã§Ä±karma
        financial_entities = self.nlp_analyzer.extract_financial_entities(text)
        
        # 4. Zamansal baÄŸlam analizi
        temporal_context = self.nlp_analyzer.analyze_temporal_context(text, publish_date)
        
        # 5. Karar kurallarÄ±nÄ± uygula
        rule_scores, rule_details = self.apply_decision_rules(text, keywords, financial_entities)
        total_score = sum(rule_scores.values())
        
        # 6. Ã–neri oluÅŸtur
        recommendation = self.generate_recommendation(total_score, rule_scores, sentiment, financial_entities)
        
        # 7. Risk analizi
        risk_analysis = self.analyze_risks(rule_scores, financial_entities, sentiment)
        
        # 8. Ã–zet Ã§Ä±kar
        summary = self.generate_summary(title, sentiment, rule_scores, recommendation, rule_details)
        
        # 9. SayÄ±sal analiz
        numerical_analysis = self.analyze_numerical_data(financial_entities)
        
        return {
            'article_info': {
                'title': title,
                'url': article.get('url'),
                'publish_date': publish_date,
                'features': article.get('features', {})
            },
            'nlp_analysis': {
                'keywords': keywords,
                'sentiment': sentiment,
                'financial_entities': financial_entities,
                'temporal_context': temporal_context,
                'numerical_analysis': numerical_analysis
            },
            'decision_analysis': {
                'rule_scores': rule_scores,
                'rule_details': rule_details,
                'total_score': total_score,
                'recommendation': recommendation,
                'risk_analysis': risk_analysis
            },
            'summary': summary
        }
    
    def apply_decision_rules(self, text: str, keywords: Dict, financial_entities: Dict) -> Tuple[Dict, Dict]:
        """Karar kurallarÄ±nÄ± uygula ve puanlarÄ± hesapla"""
        rule_scores = {}
        rule_details = {}
        text_lower = text.lower()
        
        for rule_id, rule_info in self.decision_rules.items():
            score = 0
            triggered_keywords = []
            
            # Anahtar kelimeleri kontrol et
            for keyword in rule_info['keywords']:
                if keyword in text_lower:
                    score = rule_info['score']
                    triggered_keywords.append(keyword)
            
            # Kategori anahtar kelimelerini de kontrol et
            category_keywords = keywords.get('category_keywords', {})
            for category, words in category_keywords.items():
                for word in words:
                    if any(kw in word.lower() for kw in rule_info['keywords']):
                        score = rule_info['score']
                        triggered_keywords.append(word)
            
            # Ã–zel kurallar
            if rule_id == 'K6':  # YÃ¼ksek artÄ±ÅŸ oranlarÄ±
                percentages = financial_entities.get('percentages', [])
                if any(p > 20 for p in percentages):  # %20'den yÃ¼ksek artÄ±ÅŸ
                    score = rule_info['score']
                    high_percentages = [p for p in percentages if p > 20]
                    triggered_keywords.append(f"YÃ¼ksek oranlar: {high_percentages}")
            
            rule_scores[rule_id] = score
            rule_details[rule_id] = {
                'name': rule_info['name'],
                'score': score,
                'triggered_keywords': triggered_keywords,
                'description': rule_info['description']
            }
        
        return rule_scores, rule_details
    
    def generate_recommendation(self, total_score: int, rule_scores: Dict, 
                               sentiment: Dict, financial_entities: Dict) -> Dict:
        """Toplam puana gÃ¶re Ã¶neri oluÅŸtur"""
        
        # Finansal verilere gÃ¶re ayarlama
        percentages = financial_entities.get('percentages', [])
        high_growth = any(p > 20 for p in percentages)
        
        # Temel Ã¶neri
        if total_score >= 4:
            base_recommendation = 'AL'
            confidence = 'yÃ¼ksek'
        elif total_score >= 2:
            base_recommendation = 'TUT'
            confidence = 'orta'
        elif total_score >= 0:
            base_recommendation = 'DÄ°KKATLÄ° TUT'
            confidence = 'dÃ¼ÅŸÃ¼k'
        else:
            base_recommendation = 'SAT/KAÃ‡'
            confidence = 'orta'
        
        # Duyguya gÃ¶re ayarlama
        if sentiment['dominant_sentiment'] == 'pozitif':
            if base_recommendation == 'AL':
                confidence = 'Ã§ok yÃ¼ksek'
            elif base_recommendation in ['TUT', 'DÄ°KKATLÄ° TUT']:
                base_recommendation = 'TUT'
                confidence = 'orta-yÃ¼ksek'
        elif sentiment['dominant_sentiment'] == 'negatif':
            if base_recommendation == 'AL':
                base_recommendation = 'DÄ°KKATLÄ° TUT'
                confidence = 'dÃ¼ÅŸÃ¼k'
            elif base_recommendation == 'TUT':
                base_recommendation = 'DÄ°KKATLÄ° TUT'
                confidence = 'orta'
        
        # YÃ¼ksek bÃ¼yÃ¼me varsa daha agresif Ã¶neri
        if high_growth and base_recommendation in ['TUT', 'DÄ°KKATLÄ° TUT']:
            base_recommendation = 'AL'
            confidence = 'yÃ¼ksek'
        
        # Kural bazlÄ± detaylar
        details = []
        if rule_scores.get('K1', 0) > 0:
            details.append("DÃ¼ÅŸÃ¼k kredi faizleri alÄ±m iÃ§in uygun ortam")
        if rule_scores.get('K2', 0) > 0:
            details.append("Arz azlÄ±ÄŸÄ± fiyatlarÄ± destekliyor")
        if rule_scores.get('K3', 0) > 0:
            details.append("Enflasyona karÅŸÄ± koruma Ã¶zelliÄŸi var")
        if rule_scores.get('K4', 0) < 0:
            details.append("AÅŸÄ±rÄ± deÄŸerlenme riski mevcut")
        if rule_scores.get('K5', 0) > 0:
            details.append("Ä°stanbul Ã¶zelinde gÃ¼Ã§lÃ¼ performans")
        if rule_scores.get('K6', 0) > 0:
            details.append("YÃ¼ksek artÄ±ÅŸ oranlarÄ± gÃ¶zleniyor")
        
        return {
            'action': base_recommendation,
            'confidence': confidence,
            'total_score': total_score,
            'details': details,
            'time_horizon': self.determine_time_horizon(rule_scores, sentiment, financial_entities)
        }
    
    def determine_time_horizon(self, rule_scores: Dict, sentiment: Dict, financial_entities: Dict) -> str:
        """Zaman dilimi belirle"""
        percentages = financial_entities.get('percentages', [])
        
        if rule_scores.get('K1', 0) > 0 or (percentages and max(percentages) > 30):
            return 'kÄ±sa vadeli (3-6 ay)'
        elif rule_scores.get('K3', 0) > 0:
            return 'uzun vadeli (1+ yÄ±l)'
        else:
            return 'orta vadeli (6-12 ay)'
    
    def analyze_risks(self, rule_scores: Dict, financial_entities: Dict, sentiment: Dict) -> Dict:
        """Risk analizi yap"""
        risks = []
        
        # AÅŸÄ±rÄ± deÄŸerlenme riski
        if rule_scores.get('K4', 0) < 0:
            risks.append({
                'type': 'AÅŸÄ±rÄ± deÄŸerlenme',
                'level': 'yÃ¼ksek',
                'description': 'Fiyatlar temel gÃ¶stergelerin Ã¼zerinde seyrediyor'
            })
        
        # YÃ¼ksek yÃ¼zde artÄ±ÅŸlarÄ±
        percentages = financial_entities.get('percentages', [])
        high_percentages = [p for p in percentages if p > 30]
        if high_percentages:
            risks.append({
                'type': 'Ã‡ok yÃ¼ksek artÄ±ÅŸ oranlarÄ±',
                'level': 'orta-yÃ¼ksek',
                'description': f'BazÄ± gÃ¶stergelerde %{max(high_percentages):.1f} gibi Ã§ok yÃ¼ksek artÄ±ÅŸlar'
            })
        
        # Negatif sentiment
        if sentiment['dominant_sentiment'] == 'negatif':
            risks.append({
                'type': 'Olumsuz piyasa sentimenti',
                'level': 'orta',
                'description': 'Haber tonu genel olarak olumsuz'
            })
        
        # Reel deÄŸer kaybÄ± riski
        if 'reel deÄŸer kaybÄ±' in financial_entities.get('text_preview', '').lower():
            risks.append({
                'type': 'Reel deÄŸer kaybÄ±',
                'level': 'yÃ¼ksek',
                'description': 'Enflasyon karÅŸÄ±sÄ±nda reel deÄŸer kaybÄ± yaÅŸanÄ±yor'
            })
        
        return {
            'identified_risks': risks,
            'risk_level': 'yÃ¼ksek' if any(r['level'] == 'yÃ¼ksek' for r in risks) else 'orta' if any(r['level'] == 'orta' for r in risks) else 'dÃ¼ÅŸÃ¼k',
            'risk_count': len(risks)
        }
    
    def analyze_numerical_data(self, financial_entities: Dict) -> Dict:
        """SayÄ±sal verileri analiz et"""
        percentages = financial_entities.get('percentages', [])
        
        if not percentages:
            return {'status': 'yetersiz_veri', 'message': 'Yeterli sayÄ±sal veri bulunamadÄ±'}
        
        analysis = {
            'total_percentages': len(percentages),
            'max_percentage': max(percentages),
            'min_percentage': min(percentages),
            'avg_percentage': np.mean(percentages),
            'median_percentage': np.median(percentages)
        }
        
        # BÃ¼yÃ¼me analizi
        if analysis['avg_percentage'] > 20:
            analysis['growth_trend'] = 'Ã§ok_yÃ¼ksek'
            analysis['growth_message'] = 'Ã‡ok yÃ¼ksek bÃ¼yÃ¼me oranlarÄ±'
        elif analysis['avg_percentage'] > 10:
            analysis['growth_trend'] = 'yÃ¼ksek'
            analysis['growth_message'] = 'YÃ¼ksek bÃ¼yÃ¼me oranlarÄ±'
        elif analysis['avg_percentage'] > 5:
            analysis['growth_trend'] = 'orta'
            analysis['growth_message'] = 'Orta dÃ¼zeyde bÃ¼yÃ¼me'
        else:
            analysis['growth_trend'] = 'dÃ¼ÅŸÃ¼k'
            analysis['growth_message'] = 'DÃ¼ÅŸÃ¼k bÃ¼yÃ¼me oranlarÄ±'
        
        return analysis
    
    def generate_summary(self, title: str, sentiment: Dict, rule_scores: Dict, 
                        recommendation: Dict, rule_details: Dict) -> str:
        """Analiz Ã¶zeti oluÅŸtur"""
        
        sentiment_map = {
            'pozitif': 'ğŸ“ˆ Olumlu',
            'negatif': 'ğŸ“‰ Olumsuz', 
            'nÃ¶tr': 'âš–ï¸ TarafsÄ±z'
        }
        
        sentiment_desc = sentiment_map.get(sentiment['dominant_sentiment'], 'âš–ï¸ TarafsÄ±z')
        
        active_rules = []
        for rule_id, score in rule_scores.items():
            if score != 0:
                rule_detail = rule_details.get(rule_id, {})
                active_rules.append(f"{rule_id}: {rule_detail.get('name', '')} ({score} puan)")
        
        # DetaylarÄ± formatla
        details_text = ""
        if recommendation['details']:
            details_text = "\nğŸ“‹ Detaylar:\n" + "\n".join([f"  â€¢ {d}" for d in recommendation['details']])
        
        summary = f"""
        ğŸ“Š HABER ANALÄ°Z Ã–ZETÄ°
        {'='*60}
        ğŸ“° BaÅŸlÄ±k: {title}
        ğŸ­ Sentiment: {sentiment_desc} 
          - Pozitif: %{sentiment['sentiment_ratio']['pozitif']*100:.1f}
          - Negatif: %{sentiment['sentiment_ratio']['negatif']*100:.1f}
          - NÃ¶tr: %{sentiment['sentiment_ratio']['nÃ¶tr']*100:.1f}
        
        ğŸ¯ Aktif Kurallar:
        {chr(10).join(['  â€¢ ' + r for r in active_rules]) if active_rules else '  â€¢ HiÃ§bir kural tetiklenmedi'}
        
        ğŸ’° Toplam Puan: {recommendation['total_score']}
        
        âš¡ Ã–NERÄ°: ğŸŸ¢ {recommendation['action']}
        ğŸ¯ GÃ¼ven DÃ¼zeyi: {recommendation['confidence'].upper()}
        â° Zaman Dilimi: {recommendation['time_horizon']}
        {details_text}
        """
        
        return summary


def run_analysis_on_article(article: Dict):
    """Tek bir haber iÃ§in analiz Ã§alÄ±ÅŸtÄ±r"""
    analyzer = ImprovedHousingNewsAnalyzer()
    
    print("ğŸ” Haber analiz ediliyor...")
    print(f"ğŸ“° Haber: {article.get('title')}")
    print(f"ğŸ“… Tarih: {article.get('giris', 'Bilinmiyor')}")
    print(f"ğŸ”— URL: {article.get('url')}")
    print("-" * 80)
    
    # Analizi Ã§alÄ±ÅŸtÄ±r
    analysis = analyzer.analyze_article(article)
    
    # SonuÃ§larÄ± gÃ¶ster
    print(analysis['summary'])
    
    # DetaylÄ± bilgiler
    print("\nğŸ“Š DETAYLI ANALÄ°Z:")
    print(f"Top 10 Anahtar Kelimeler:")
    for word, freq in list(analysis['nlp_analysis']['keywords']['top_keywords'].items())[:10]:
        print(f"  ğŸ“Œ {word}: {freq}")
    
    print(f"\nğŸ·ï¸ Kategori Anahtar Kelimeleri:")
    cats = analysis['nlp_analysis']['keywords']['category_keywords']
    for category, words in cats.items():
        if words:
            print(f"  ğŸ”¹ {category}: {', '.join(words[:3])}")
    
    print(f"\nğŸ“ˆ Finansal Veriler:")
    fin = analysis['nlp_analysis']['financial_entities']
    if fin['percentages']:
        print(f"  ğŸ“Š YÃ¼zde OranlarÄ±: {fin['percentages']}")
        print(f"  ğŸ“ˆ En YÃ¼ksek: %{fin['max_percentage']:.1f}")
        print(f"  ğŸ“‰ En DÃ¼ÅŸÃ¼k: %{fin['min_percentage']:.1f}")
        print(f"  âš–ï¸ Ortalama: %{fin['avg_percentage']:.1f}")
    else:
        print("  âŒ Finansal veri bulunamadÄ±")
    
    print(f"\nğŸ­ Duygu Analizi DetayÄ±:")
    sent = analysis['nlp_analysis']['sentiment']
    print(f"  ğŸ˜Š Pozitif CÃ¼mleler: {sent['positive_sentences']}")
    print(f"  â˜¹ï¸ Negatif CÃ¼mleler: {sent['negative_sentences']}")
    print(f"  ğŸ˜ NÃ¶tr CÃ¼mleler: {sent['neutral_sentences']}")
    
    print(f"\nâš–ï¸ Karar Analizi DetayÄ±:")
    for rule_id, detail in analysis['decision_analysis']['rule_details'].items():
        if detail['score'] != 0:
            print(f"  âœ… {detail['name']}: {detail['score']} puan")
            if detail['triggered_keywords']:
                print(f"     Tetikleyenler: {', '.join(detail['triggered_keywords'][:3])}")
    
    print(f"\nâš ï¸ Risk Analizi:")
    risks = analysis['decision_analysis']['risk_analysis']['identified_risks']
    if risks:
        for risk in risks:
            level_icon = 'ğŸ”´' if risk['level'] == 'yÃ¼ksek' else 'ğŸŸ¡' if risk['level'] == 'orta' else 'ğŸŸ¢'
            print(f"  {level_icon} {risk['type']} ({risk['level']}): {risk['description']}")
    else:
        print("  âœ… Belirgin risk bulunamadÄ±")
    
    print("\n" + "="*80)
    
    return analysis


# Ana Ã§alÄ±ÅŸtÄ±rma kodu
if __name__ == "__main__":
    print("ğŸš€ GELÄ°ÅMÄ°Å BLOOMBERGHT KONUT HABER ANALÄ°Z SÄ°STEMÄ°")
    print("="*80)
    
    # Ã–nce haberleri Ã§ek
    print("\nğŸ“¥ BloombergHT'den konut haberleri Ã§ekiliyor...")
    articles = crawl_bloomberght_konut_tr_ist(max_results=1)
    
    if articles:
        # Ä°lk haberi analiz et
        article = articles[0]
        
        # NLP analizini Ã§alÄ±ÅŸtÄ±r
        analysis_result = run_analysis_on_article(article)
        
        # JSON olarak kaydet
        with open('haber_analizi_detayli.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2, default=str)
        
        print("âœ… Analiz tamamlandÄ± ve 'haber_analizi_detayli.json' dosyasÄ±na kaydedildi.")
        
        # Senaryodaki formatta Ã¶neri oluÅŸtur
        print("\n" + "="*80)
        print("ğŸ“‹ SENARYO FORMATINDA Ã–NERÄ°:")
        print("="*80)
        
        rec = analysis_result['decision_analysis']['recommendation']
        risks = analysis_result['decision_analysis']['risk_analysis']
        
        print(f"\nA. Ev DeÄŸeri Tahmini (Risk/Potansiyel)")
        print(f"   Toplam Etki PuanÄ±: {rec['total_score']}")
        
        if rec['total_score'] >= 4:
            degerlendirme = "ğŸš€ GÃ¼Ã§lÃ¼ YÃ¼kselme Potansiyeli"
        elif rec['total_score'] >= 2:
            degerlendirme = "ğŸ“ˆ Orta Seviyede YÃ¼kselme Potansiyeli"
        elif rec['total_score'] >= 0:
            degerlendirme = "âš–ï¸ SÄ±nÄ±rlÄ± YÃ¼kselme Potansiyeli"
        else:
            degerlendirme = "âš ï¸ DÃ¼ÅŸÃ¼ÅŸ Riski Mevcut"
        
        print(f"   DeÄŸerlendirme: {degerlendirme}")
        print(f"   Risk Seviyesi: {risks['risk_level'].upper()}")
        
        if rec['details']:
            gerekce = " ".join(rec['details'][:2])
        else:
            gerekce = "Temel analiz gÃ¶stergeleri sÄ±nÄ±rlÄ±"
        
        print(f"   GerekÃ§e: {gerekce}")
        
        # SayÄ±sal tahmin
        fin = analysis_result['nlp_analysis']['financial_entities']
        if fin.get('percentages'):
            avg_growth = fin['avg_percentage']
            tahmin = f"Ã–nÃ¼mÃ¼zdeki 6 ay iÃ§inde Ä°stanbul genelinde %{avg_growth:.1f} - %{avg_growth+2:.1f} arasÄ± deÄŸer artÄ±ÅŸÄ± beklentisi"
        else:
            tahmin = "Yeterli sayÄ±sal veri olmadÄ±ÄŸÄ±ndan tahmin yapÄ±lamÄ±yor"
        
        print(f"   Tahmini ArtÄ±ÅŸ: {tahmin}")
        
        print(f"\nB. Ã–neri (Al/Sat/Tut)")
        print(f"   Ã–neri Kategorisi: {rec['action']}")
        print(f"   GÃ¼ven DÃ¼zeyi: {rec['confidence'].upper()}")
        
        if rec['action'] == 'AL':
            aciklama = "ALIM iÃ§in uygun bir zaman diliminde bulunuluyor. DÃ¼ÅŸÃ¼k faiz ortamÄ± ve artan talep fiyatlarÄ± destekliyor."
        elif rec['action'] == 'TUT':
            aciklama = "TUTMAK mantÄ±klÄ± gÃ¶rÃ¼nÃ¼yor. Piyasa dengeleri korunuyor, enflasyona karÅŸÄ± koruma Ã¶zelliÄŸi devam ediyor."
        elif rec['action'] == 'DÄ°KKATLÄ° TUT':
            aciklama = "DÄ°KKATLÄ° TUTMAK Ã¶nerilir. BazÄ± risk faktÃ¶rleri mevcut, yakÄ±n takip gerekiyor."
        else:
            aciklama = "SAT/KAÃ‡ Ã¶nerilmektedir. Risk faktÃ¶rleri baskÄ±n, korunma amaÃ§lÄ± hareket edilmeli."
        
        print(f"   AÃ§Ä±klama: {aciklama}")
        print(f"   Eylem Tavsiyesi: {rec['time_horizon']} perspektifle hareket edilmesi Ã¶nerilir.")
        
        print(f"\nC. Risk UyarÄ±larÄ±:")
        if risks['identified_risks']:
            for risk in risks['identified_risks']:
                print(f"   âš ï¸ {risk['type']}: {risk['description']}")
        else:
            print("   âœ… Ã–nemli risk faktÃ¶rÃ¼ tespit edilmedi")
    else:
        print("âŒ Analiz edilecek haber bulunamadÄ±.")